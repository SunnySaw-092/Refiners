script = "finetune-ldm-color-palette.py" # not used for now
[wandb]
mode = "online" # "online", "offline", "disabled"
entity = "piercus"
project = "histogram"
name="loss0.2-adam-step-lr"

[models]
unet = {checkpoint = "tests/weights/stable-diffusion-1-5/unet.safetensors", gpu_index=0, train = false}
text_encoder = {checkpoint = "tests/weights/stable-diffusion-1-5/CLIPTextEncoderL.safetensors", gpu_index=1, train = false}
lda = {checkpoint = "tests/weights/stable-diffusion-1-5/lda.safetensors", gpu_index=1, train = false}
histogram_encoder = {gpu_index=0, train = true}

[latent_diffusion]
unconditional_sampling_probability = 0.1
offset_noise = 0.1

[histogram]
max_colors = 8
feedforward_dim = 128
num_attention_heads = 2
num_layers = 2
embedding_dim = 128
color_bits = 5 # 2^5 = 32 color-level => 32Â³ different colors 32 768 colors
patch_size = 8 # (2^5/8)^3 + 1 => sequence of 65 tokens
loss_weight = 0.1

[training]
duration = "1:epoch"
seed = 0
gpu_index = 0
batch_size = 1
gradient_accumulation = "1:step"
clip_grad_norm = 1.0
# clip_grad_value = 1.0
evaluation_interval = "1000:step"
evaluation_seed = 1

[optimizer]
optimizer = "AdamW" # "SGD", "Adam", "AdamW", "AdamW8bit", "Lion8bit"
learning_rate = 2e-4
betas = [0.9, 0.999]
eps = 1e-8
weight_decay = 1e-2

[scheduler]
scheduler_type = "ConstantLR"
update_interval = "1:step"
warmup = "1000:step"

[dropout]
dropout_probability = 0.0
use_gyro_dropout = false

[dataset]
hf_repo = "1aurent/unsplash-lite-palette"
revision = "main"
resize_image_max_size = 512
caption_key = "ai_description"
split = "train"
#random_crop = false

[checkpointing]
#save_folder = "ckpts"
save_interval = "10000:step"

[test_histogram]
num_inference_steps = 30
use_short_prompts = false
prompts = [
        {"text" = "a cute cat", "histogram_db_index" = 0},
        {"text" = "a cute cat", "histogram_db_index" = 1},
        {"text" = "a cute cat", "histogram_db_index" = 2},
        {"text" = "a cute cat", "histogram_db_index" = 3}
]
num_samples = 8
condition_scale = 1.0 # deactivate cause negative sampling not well defined
